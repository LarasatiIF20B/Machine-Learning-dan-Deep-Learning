{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks 3**"
      ],
      "metadata": {
        "id": "GdpyBRkDaBnY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OEvcE4tZ6so",
        "outputId": "9d1ba1a0-1a2e-41fd-b523-c500934b550c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 82186227.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 62764608.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 19437034.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13875111.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Transformasi data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Memuat dataset MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "# Membuat dataloader\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memulai loop untuk mendapatkan satu batch dari data pelatihan\n",
        "for images, labels in train_loader:\n",
        "    pass  # perlu mengganti dengan pemrosesan sesuai kebutuhan"
      ],
      "metadata": {
        "id": "LZ5W3PawakBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor modul neural network (nn) dan fungsi aktivasi dari PyTorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Definisi kelas SimpleNN yang merupakan subclass dari nn.Module\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "       # Memanggil konstruktor kelas induk (nn.Module)\n",
        "        super(SimpleNN, self).__init__()\n",
        "        # Layer pertama (fully connected) dengan input_size neuron dan hidden_size neuron\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        # Layer kedua (fully connected) dengan hidden_size neuron dan num_classes neuron\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    # Metode forward untuk mendefinisikan aliran data melalui model\n",
        "    def forward(self, x):\n",
        "      # Terapkan fungsi aktivasi ReLU pada hasil layer pertama\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Langsung terapkan layer kedua tanpa fungsi aktivasi (untuk klasifikasi)\n",
        "        x = self.fc2(x)\n",
        "        # Kembalikan hasilnya\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_size = 28 * 28  # Ukuran gambar MNIST adalah 28x28\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "model = SimpleNN(input_size, hidden_size, num_classes)"
      ],
      "metadata": {
        "id": "0tk2AFKDavyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisi fungsi loss menggunakan CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Definisi optimizer menggunakan algoritma Adam, dengan learning rate yang telah ditentukan\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Os70--yNa23g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisi jumlah epoch untuk pelatihan\n",
        "num_epochs = 5\n",
        "\n",
        "# Iterasi melalui setiap epoch\n",
        "for epoch in range(num_epochs):\n",
        "   # Inisialisasi total loss untuk setiap epoch\n",
        "    total_loss = 0\n",
        "    # Iterasi melalui setiap batch dalam data pelatihan menggunakan train_loader\n",
        "    for images, labels in train_loader:\n",
        "      # Melakukan flattening pada gambar agar sesuai dengan input model\n",
        "        images = images.view(-1, 28 * 28)  # Flatten the images\n",
        "         # Mendapatkan output dari model untuk batch saat ini\n",
        "        outputs = model(images)\n",
        "        # Menghitung loss menggunakan fungsi loss (CrossEntropyLoss)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Mengatur gradien parameter model menjadi 0\n",
        "        optimizer.zero_grad()\n",
        "        # Melakukan backpropagation untuk menghitung gradien loss\n",
        "        loss.backward()\n",
        "        # Melakukan langkah optimasi berdasarkan gradien yang dihitung\n",
        "        optimizer.step()\n",
        "        # Menambahkan loss pada batch saat ini ke total loss untuk epoch ini\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Mencetak rata-rata loss untuk epoch ini\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3i0S2D_bF9H",
        "outputId": "e6078122-7bcc-4610-ddd2-923575dd6cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.09566045389113538\n",
            "Epoch 2, Loss: 0.08645134920359596\n",
            "Epoch 3, Loss: 0.07678621033725859\n",
            "Epoch 4, Loss: 0.0703288556534801\n",
            "Epoch 5, Loss: 0.06499459071115636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi hitungan untuk evaluasi akurasi model\n",
        "correct = 0 # jumlah prediksi yang benar\n",
        "total = 0 # total jumlah gambar yang dievaluasi\n",
        "model.eval() # Mengubah mode model menjadi evaluasi (non-pelatihan)\n",
        "\n",
        "# Tidak melakukan perhitungan gradien selama evaluasi\n",
        "with torch.no_grad():\n",
        "  # Iterasi melalui setiap batch dalam data uji menggunakan test_loader\n",
        "    for images, labels in test_loader:\n",
        "      # Melakukan flattening pada gambar agar sesuai dengan input model\n",
        "        images = images.view(-1, 28 * 28)\n",
        "        # Mendapatkan output dari model untuk batch saat ini\n",
        "        outputs = model(images)\n",
        "        # Mengambil indeks kelas prediksi dengan nilai tertinggi\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # Menambahkan jumlah gambar pada batch saat ini ke total\n",
        "        total += labels.size(0)\n",
        "        # Menambahkan jumlah prediksi yang benar dengan menghitung kesamaan dengan label sebenarnya\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Menghitung dan mencetak akurasi\n",
        "print('Akurasi pada gambar uji: {:.2f}%'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og_Mj6MtdrOw",
        "outputId": "f3efd9b8-465b-41ae-cce2-40da139eeda6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi pada gambar uji: 97.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Fungsi untuk mendapatkan prediksi dari model\n",
        "def get_all_predictions(model, data_loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.view(-1, 28 * 28)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted)\n",
        "            all_labels.extend(labels)\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Mendapatkan prediksi dari model pada data uji\n",
        "predictions, true_labels = get_all_predictions(model, test_loader)\n",
        "\n",
        "# Menghitung akurasi\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print('Akurasi: {:.2f}%'.format(accuracy * 100))\n",
        "\n",
        "# Membuat matriks kebingungan\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Menghitung F1 Score, presisi, dan recall\n",
        "report = classification_report(true_labels, predictions, target_names=[str(i) for i in range(10)])\n",
        "print('Laporan Klasifikasi:')\n",
        "print(report)"
      ],
      "metadata": {
        "id": "P49uVjepd9rl",
        "outputId": "c2170e1b-5681-4489-ead2-19cde81182f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi: 97.11%\n",
            "Confusion Matrix:\n",
            "[[ 968    0    0    2    1    3    0    3    1    2]\n",
            " [   0 1122    3    2    0    1    3    0    4    0]\n",
            " [   4    0 1010    9    1    0    2    2    4    0]\n",
            " [   0    0    5  997    0    3    0    1    2    2]\n",
            " [   1    0    3    1  950    0    6    2    2   17]\n",
            " [   3    0    0   19    1  862    3    0    3    1]\n",
            " [   5    2    1    1    2    3  943    0    1    0]\n",
            " [   0    6   22   20    0    1    1  967    1   10]\n",
            " [   4    2    6   20    5    5    6    2  922    2]\n",
            " [   2    3    0   18    6    5    2    2    1  970]]\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.96      0.98      0.97      1032\n",
            "           3       0.92      0.99      0.95      1010\n",
            "           4       0.98      0.97      0.98       982\n",
            "           5       0.98      0.97      0.97       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.99      0.94      0.96      1028\n",
            "           8       0.98      0.95      0.96       974\n",
            "           9       0.97      0.96      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}